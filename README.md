# Rock-Paper-Scissors Computer Vision Game

## Description

This project is a computer vision-based implementation of the classic game Rock-Paper-Scissors. Using a model trained with Teachable Machine, it allows players to play Rock-Paper-Scissors against the computer by showing their choice to a camera. The project aims to explore and apply machine learning and computer vision concepts by creating an interactive game that can recognize and interpret human gestures.


## Installation

*Note: These instructions are preliminary and will be updated as the project progresses.*

1. Clone this repository to your local machine.
2. Ensure you have Python installed on your system. This project requires Python 3.6 or later.
3. Install the required Python packages. (A requirements.txt file will be provided in future updates for easy installation of dependencies.)

## Usage

*Usage instructions will be provided in later stages of the project, detailing how to start the game and interact with it using hand gestures.*

## Project Structure

- `README.md`: This file, providing an overview of the project, installation instructions, usage guide, and other important information.
- `RPS-Template.py`: The main Python script for the Rock-Paper-Scissors game. It includes the logic for interfacing with the computer vision model and processing the game mechanics.
- `keras_model.h5`: The trained model file. This deep learning model is trained to recognize hand gestures for rock, paper, and scissors.
- `labels.txt`: Contains the labels for the model, correlating to the gestures recognized by the game (rock, paper, scissors, and "nothing").

## Progress and Learning

This project is currently in its initial stages, focusing on setting up the foundational elements:

- Training a computer vision model using Teachable Machine with images representing the gestures for rock, paper, scissors, and a "nothing" class.
- Integrating the trained model into a Python application to interpret the user's gestures through a webcam interface.

As the project progresses, this section will be updated to reflect new developments, challenges encountered, and solutions implemented.

## License

This project is licensed under the MIT License 
